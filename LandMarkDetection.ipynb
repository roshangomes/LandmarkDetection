{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "poRMtq99RV7d"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "PdldLFnvT8PK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "id": "RW_YoLZjUEPp",
    "outputId": "b556087c-eeed-4b96-c313-2222fa98fb05"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "9GsE8xbTUrQN"
   },
   "outputs": [],
   "source": [
    "samples = 20000\n",
    "df = df[df[\"id\"].astype(str).str.startswith('00')]\n",
    "num_classes = len(df[\"landmark_id\"].unique())\n",
    "num_data = len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "in_DKtB4Vvhm",
    "outputId": "fb5b348d-2c2b-4b07-eaf4-b01c5843b74b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13589"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nKRgwVgxV0xo",
    "outputId": "da80eac8-2bba-48c4-ebc6-c2f56496da9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16157"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "NyrnS30CV6Z0",
    "outputId": "e2a9d7f5-40cc-49cc-96b5-4fb6a56345de"
   },
   "outputs": [],
   "source": [
    "data = pd.DataFrame(df[\"landmark_id\"].value_counts())\n",
    "\n",
    "data.reset_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "YNa7Q-0EWpkG",
    "outputId": "26a0219f-4f7b-49eb-aee5-7542dd982e85"
   },
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "Yq8ceywyWvAC"
   },
   "outputs": [],
   "source": [
    "data.columns=['index','landmark_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 335
    },
    "id": "CRoMXtYNXsVZ",
    "outputId": "aeb5d171-2787-4fec-abf4-5def476a0232"
   },
   "outputs": [],
   "source": [
    "data['index'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "mqsH2t6DX4gf",
    "outputId": "3f55aabc-ebd3-4db4-f7eb-117e43b04313"
   },
   "outputs": [],
   "source": [
    "plt.hist(data['landmark_id'],100,range=(0,58),label='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i6Qq5wHbYgm2",
    "outputId": "4b84db08-170f-4d68-b324-9d2c51325e6d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13549"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['landmark_id'].between(0,5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dhgQkxXEYt12",
    "outputId": "5ec53082-9d38-466d-e7ed-e74e0f28aa57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['landmark_id'].between(5,10).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 501
    },
    "id": "H4Q1EKRRZenB",
    "outputId": "e170cadc-d9cb-442a-f33e-c7abb6a9bdf7"
   },
   "outputs": [],
   "source": [
    "plt.hist(df[\"landmark_id\"], bins=sorted(df[\"landmark_id\"].unique()))\n",
    "# Sort the unique values to ensure monotonically increasing bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "id": "VOYaXD6yZwY-",
    "outputId": "d1dd985b-fcf2-4779-b333-e2770a2c59f7"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lencoder = LabelEncoder()\n",
    "lencoder.fit(df[\"landmark_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "zF-b0VLJaQFd",
    "outputId": "97e161dc-1b47-4f23-ded7-7c61e20245a2"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "vwUwpfybaWe4"
   },
   "outputs": [],
   "source": [
    "def encode_label(label):\n",
    "    return lencoder.transform(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "kIJC2jYqaoxU"
   },
   "outputs": [],
   "source": [
    "def decode_label(label):\n",
    "    return lencoder.inverse_transform(lbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "HrsHQfOjczPr"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_image_from_number(num):\n",
    "    fname, label = df.loc[num, :]\n",
    "    fname = fname + '.jpg'\n",
    "    f1 = fname[0]\n",
    "    f2 = fname[1]\n",
    "    f3 = fname[2]\n",
    "    path = os.path.join(f1, f2, f3, fname)\n",
    "    im = cv2.imread(os.path.join(base_path, path))\n",
    "    return im, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xm-OzmaZwx9-"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import *\n",
    "from keras import Sequential\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C48yDCWbxMoO"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.0001\n",
    "decay_speed = 1e6\n",
    "momentum = 0.09\n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "source_model = VGG19(weights=None)\n",
    "drop_layer = Dropout(0.5)\n",
    "drop_layer2 = Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zjmIqtI0y1cF"
   },
   "outputs": [],
   "source": [
    "model - Sequential()\n",
    "for layer in source_nodel. layers[:-1]:\n",
    "  if layer == source_nodel.layers[- 25]:\n",
    "     model. add (Batchilornalization())\n",
    "  model.add(layer)\n",
    "nodel. add(Dense(nun_classes, activation « \"softnax\"))\n",
    "model. summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gSaH0eLjRN0"
   },
   "outputs": [],
   "source": [
    "optim1 = keras.optimizer_v1.RMSprop(Ir = learning_rate)\n",
    "model. conplle(optimizer-optima,loss-loss_function,\n",
    "netries - (\"accuracy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oxltt8GPeoKD"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y6b_jg2wjn2k"
   },
   "outputs": [],
   "source": [
    "def image_reshape(im, target_size):\n",
    "return cv2.resize(im, target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p9-zolPIjt3b"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_batch(dataframe, start, batch_size):\n",
    "    \"\"\"\n",
    "    Fetches a batch of images and labels from the dataframe.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): Dataframe containing image IDs and labels.\n",
    "        start (int): Starting index for the batch.\n",
    "        batch_size (int): Size of the batch.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[np.ndarray, np.ndarray]: A tuple containing the image array and label array.\n",
    "    \"\"\"\n",
    "    image_array = []\n",
    "    label_array = []\n",
    "    end_ing = start + batch_size  # Corrected variable name and calculation\n",
    "\n",
    "    if end_ing > len(dataframe):  # Corrected condition\n",
    "        end_ing = len(dataframe)  # Corrected assignment\n",
    "\n",
    "    for idx in range(start, end_ing):  # Corrected loop variable name\n",
    "        im, label = get_image_from_number(idx, dataframe)  # Corrected function call and variable names\n",
    "        im = image_reshape(im, (224, 224)) / 255.0  # Corrected function call and variable name\n",
    "        image_array.append(im)  # Corrected variable name\n",
    "        label_array.append(label)  # Corrected variable name\n",
    "\n",
    "    label_array = encode_label(label_array)  # Corrected function call and variable name\n",
    "    return np.array(image_array), np.array(label_array)  # Corrected variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h9fXX-VMkSxc"
   },
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epoch_shuffle = True\n",
    "weight_classes = True\n",
    "epochs - 1\n",
    "# split\n",
    "train, val - np.split(df.sanple(frac-1),[Int(0.8*len(df))])\n",
    "print(len(train) )\n",
    "print(len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-EG4YnUwk6NV"
   },
   "outputs": [],
   "source": [
    "for e in range(epochs) :\n",
    "   print(\"Epoch:\" • str (er1) + */™» str(epochs))\n",
    "     if epoch_shuffle:\n",
    "        train = train.sanple(frac- 1)\n",
    "    for It in range(int(np.cell(len(train)/batch_size))):\n",
    "        X train, Y_train - get_batch(train, It*batch_size, batch_size)\n",
    "        model. train _on_batch(X_train, y_train)\n",
    "model, save (\"Model\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8JhA9vv5lmOx"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# ... (Assuming get_batch, get_image_from_number, and model are defined) ...\n",
    "\n",
    "batch_size = 16\n",
    "errors = 0  # Initialize errors to 0\n",
    "good_preds = []\n",
    "bad_preds = []\n",
    "\n",
    "for it in range(int(np.ceil(len(val) / batch_size))):  # Corrected np.cell to np.ceil\n",
    "    X_val, Y_val = get_batch(val, it * batch_size, batch_size)  # Corrected It to it\n",
    "    result = model.predict(X_val)  # Assuming 'model' is your trained model\n",
    "    cla = np.argmax(result, axis=1)  # Corrected axis-1 to axis=1\n",
    "\n",
    "    for idx, res in enumerate(result):  # Corrected 1dx to idx\n",
    "        if cla[idx] == Y_val[idx]:  # Corrected y_val to Y_val and 1 to ==\n",
    "            good_preds.append([batch_size * it + idx, cla[idx], res[cla[idx]]])  # Corrected 1dx to idx\n",
    "        else:\n",
    "            errors += 1  # Increment errors for incorrect predictions\n",
    "            bad_preds.append([batch_size * it + idx, cla[idx], res[cla[idx]]])  # Corrected 1dx to idx\n",
    "\n",
    "# Display some good predictions\n",
    "for i in range(min(5, len(good_preds))):  # Limit to 5 or fewer predictions\n",
    "    n = good_preds[i][0]  # Get image index from good_preds\n",
    "    img, lbl = get_image_from_number(n, val)  # Get image and label\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert to RGB for plt.imshow\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {good_preds[i][1]}, Actual: {lbl}\")  # Add title with prediction and actual label\n",
    "    plt.show()\n",
    "\n",
    "print(f\"Total Errors: {errors}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
